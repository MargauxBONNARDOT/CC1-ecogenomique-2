---
title: "Workflow for Microbiome Data Analysis: from raw reads to community analyses"
output: github_document
---

#Workflow for Microbiome Data Analysis: from raw reads to community analyses.

##Methods
###Amplicon bioinformatics: from raw reads to tables

```{bash, include = FALSE}
#sudo apt-get update -y
#sudo apt-get install -y libglpk-dev 
#sudo apt-get install -y liblzma-dev libbz2-dev
```

```{r}
library("knitr")
library("BiocStyle")
.cran_packages <- c("ggplot2", "gridExtra", "devtools")

.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)

.cran_packages <- c( "shiny","miniUI", "caret", "pls", "e1071", "ggplot2", "randomForest", "dplyr", "ggrepel", "nlme", "devtools",
                  "reshape2", "PMA", "structSSI", "ade4",
                  "ggnetwork", "intergraph", "scales")
.github_packages <- c("jfukuyama/phyloseqGraphTest")
.bioc_packages <- c("genefilter", "impute")
```

```{r, include = FALSE}
# package de r-studio
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("BiocStyle")
#BiocManager::install("Rhtslib")
#biocmanager est un site de depot, les pakages depedent d'autres packages et biomarqueur regle tous pour nous
# on verif que tous a ete installé et on instale d'autre trucs
```

```{r, include=FALSE}
#library("knitr")
#library("BiocStyle")
#.cran_packages <- c("ggplot2", "gridExtra", "devtools")
#install.packages(.cran_packages) 
#.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
#BiocManager::install(.bioc_packages)
# Load packages into session, and print package version
#sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
```

```{bash, include = FALSE}
#cd~
#wget https://mothur.s3.us-east-2.amazonaws.com/wiki/miseqsopdata.zip
#unzip miseqsopdata.zip
```

```{r}
set.seed(100)
miseq_path <- "./MiSeq_SOP" 
list.files(miseq_path)
```

```{r}
set.seed(100)
miseq_path <- "/home/rstudio/MiSeq_SOP"
list.files(miseq_path)
```


```{r, include=FALSE}
# Si on quite R(pas R studio) il faut run ca pour qu'il ait bien les packages
```

```{r}
.cran_packages <- c("ggplot2", "gridExtra", "devtools")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
```

###Filter and Trim

Sort to unsure foward and reverse reads are in the same order

```{r}
fnFs <- sort(list.files(miseq_path, pattern="_R1_001.fastq"))
fnRs <- sort(list.files(miseq_path, pattern="_R2_001.fastq"))
```

```{r, include = FALSE}
# Commentaires

#F c'est pour foward et R pour reverse
# apply
# on garde que ce qui est séparé par underscore

# on change ce qu'il y a ds objets
# contruire un chemin vers fichier à partir de composant, independant de la plateforme
```

Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq

```{r}
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
```

```{r}
fnFs[1:3] #affiches les 3 premier elements de fnFs
fnRs[1:3]
```


Most Illumina sequencing data shows a trend of decreasing average quality towards the end of sequencing reads.
The first two forward reads:

```{r, include = FALSE}
# va lire les 2 premiers elements en Foward
# score de qualité
#heat map de la freq des score de qualité pour chacune des positions
# donc en noir: pour tous les read, le score de qualité associé a chacune des bases le plus frequent c'est 38
#bon score de qualité vers 38/39
# Q score va de 0 à 50, à 30, 1/1000 chance (en fait y'3 zero =30) que cette base la est pas la bonne base

#la ligne rouge:
#illumina: read de 250
#--> distribution des longueur de read
#plus une seq est longue, plus on a d'erreur

#perte de qualité à partir d'une longueur de 125
# a fin de seq on a score de qualité de 25


# Nous on veut garder que les sequences de bonnes qualité
# illumina faut 2x250bp
# V4 fait 300pb
# on va essayer aligner foward et reverse pour reformer les v4
#mais si on enleve toute mauvase qualité, ca enleve le chevauchement!!! donc faut conserver alignement (au moins 1à, mais vauut mieux alignement de 20)


#Here, the forward reads maintain high quality throughout, while the quality of the reverse reads drops significantly #at about position 160. Therefore, we choose to truncate the forward reads at position 245, and the reverse reads at #position 160. 
#We also choose to trim the first 10 nucleotides of each read based on empirical observations across many Illumina #datasets that these base positions are particularly likely to contain pathological errors.
#la fonction plotQualityProfile s'en charge

```

```{r}
# Pour les foward
plotQualityProfile(fnFs[1:2])

# Pour les reverse
plotQualityProfile(fnRs[1:2])
```
We define the filenames for the filtered fastq.gz files:

```{r, include=FALSE}
#on creer un path filtered
  # on le met dans filtered/ subdirectory

# pour filt_path = "filtered" est le nouv endroit ou ya. nos objet

# dans le if 
#le -d correspond à un element du file path
  # si file_test n'est pas -d et dans le filtered path, alors dir.create provide a low-level
  #interface to the computer's file system.

 #filtFs = filtered path pour les fowards, on cherche le filtered path et on trie par le nom du sample
```

```{r}
filt_path <- file.path(miseq_path, "filtered") 

if(!file_test("-d", filt_path)) 
  dir.create(filt_path)


filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fasta.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))
```

Filter the forward and reverse reads:

```{r, include=FALSE}
# combine trimming parameters with standard filtering parameters

# Filter the forward and reverse reads:
# on utilise filter and tim
# cette fonction prend une fichier fastq suivant certain critère def et contient les reads trimmed
# en imput on met les files de reverse et foward
# dans ce cas le filtering is performed on the forward and reverse reads independently, and both reads must pass for the read pair to be output.
```


```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160), maxN=0, maxEE=c(2,2),truncQ=2, rm.phix=TRUE,compress=TRUE, multithread=TRUE)
# out filte et compresse tous ca dans le fichier

# On Windows set multithread=FALSE
head(out)
```


###Infer sequence variants

```{r}
# Infer sequence variants

  #  high-resolution DADA2 method
  # --> infer amplicon sequence variants (ASVs) 
  # name the resulting "derep-class" objects by their sample name.


# Dereplication
  # la fonction de replicating amplicon sequences from fastq or compressed fastq files, while also controlling peak memory   requirement to support large files.
  # combines all identical sequencing reads into into “unique sequences” # with a corresponding “abundance”

```
#### Dereplication

```{r}
  derepFs <- derepFastq(filtFs, verbose=TRUE)
  derepRs <- derepFastq(filtRs, verbose=TRUE)

# Name the derep-class objects by the sample names
  names(derepFs) <- sampleNames #en fait il recoivent les nom des ech
  names(derepRs) <- sampleNames

```

```{r}
  errF <- learnErrors(filtFs, multithread=TRUE) 
```

```{r}
  errR <- learnErrors(filtRs, multithread=TRUE)
```

```{r, include=FALSE}
# error F ou R 

  # 33514080 total bases in 139642 reads from 20 samples will be used for #learning the error rates.
  #22342720 total bases in 139642 reads from 20 samples will be used for #learning the error rates.
  # --> ce sont les profil d'erreur

  # verify that the error rates
  # --> show the frequencies of each type of transition as a function of #the quality.
  #pour chacune des mutation posible: que A remplace A à une proba tres haute, ou C par C, T par T ......

  # difference entre OTU (a cause erreur de seq, on a pleins de variant)
  # si on retire variant, on a plus OTU, donc 2 unité ecologique proches sont considéré comme pareille
```

```{r}
  plotErrors(errF)
  plotErrors(errR)
```

Pooling improves the detection of rare variants
```{r}
  dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
  dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
```

Inspecting the dada-class object returned by dada:
```{r}  
  dadaFs[[1]]  
```

```{r, include=FALSE} 
#dadaFs[[1]] est une
#liste de liste
  # 128 sequence variants were inferred from 1979
```

###Construct sequence table and remove chimeras

```{r}
  # sequence table --> sample by sequence feature table valued by the 
  # number of times each sequence was observed in each sample.

  # merge each denoised pair of forward and reverse reads, rejecting any pairs which do not 
  # sufficiently overlap or contain too many

  # cnostruction table seq qui resume combien de fois est obs chacun des asv
  # 251 252 253 254 255 
  #  1  85 186   5   2
  # Notably, chimeras have not yet been removed
  #nombre de fois dans lequel apparaissent echantillions

  # chimerasmake up about 22% of the inferred sequence variants
  # but they are rare (4%)
```

```{r}
  mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)

  seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
  table(nchar(getSequences(seqtabAll)))

  seqtabNoC <- removeBimeraDenovo(seqtabAll)
  seqtabNoC
```

Les chimères contituent environ 22% des variants mais ont une abondance rare de 4%

###Assign taxonomy
```{r, include=FALSE}
# Assign taxonomy
  # --> dada2 package, va comparer les otu qu'ona fomer et va les identifier ?
  # --> cluster à 97% d'identifier

  # on doit telecharger :   silva_nr99_v138.1_train_set.fa
  # faut le mettre sur la VM

  #fastaRef <- "/home/rdp_train_set_16.fa.gz"
  #taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread=TRUE) 
  #unname(head(taxTab))

  #fastaRef <- "/home/ecogenomique2/ecogenomiqueM1MFAprojet/silva_nr99_v138.1_train_set.fa"
```

```{r}
  fastaRef <- "/home/rstudio/silva_nr99_v138.1_train_set.fa"
  taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread=TRUE) 
  unname(head(taxTab))
```  
  
```{r}
  taxTab
```

###Construct phylogenetic tree

```{r, include=FALSE}
#Construct phylogenetic tree

  #calculation of phylogeny-aware distances between microbial communities

# seqs = fonction de dada 2 qui recup seq ds seqtaNoC auquel ont a enelevé les chimere
  # montre niv occurence de chaque ech
  # table d'obs

# names
  # This propagates to the tip labels of the tree
```

```{r}
  seqs <- getSequences(seqtabNoC) 
  names(seqs) <- seqs 
  alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

The phangorn R package is then used to construct a phylogenetic tree
```{r}
  phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
  dm <- dist.ml(phangAlign)
  treeNJ <- NJ(dm) # Note, tip order != sequence order
  fit = pml(treeNJ, data=phangAlign)
  fitGTR <- update(fit, k=4, inv=0.2)
  fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
     detach("package:phangorn", unload=TRUE)
```

```{r}
  fitGTR
  plot(fitGTR)
```

###Combine data into a phyloseq object

```{r}
ps_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
```

Combine data into a phyloseq object
```{r}
  samdf <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/MIMARKS_Data_combined.csv",header=TRUE)
  samdf$SampleID <- paste0(gsub("00", "", samdf$host_subject_id), "D", samdf$age-21)
  samdf <- samdf[!duplicated(samdf$SampleID),] # Remove dupicate entries for reverse reads
  rownames(seqtabAll) <- gsub("124", "125", rownames(seqtabAll)) # Fix discrepancy
  all(rownames(seqtabAll) %in% samdf$SampleID) # TRUE
```

```{r}
  rownames(samdf) <- samdf$SampleID
  keep.cols <- c("collection_date", "biome", "target_gene", "target_subfragment","host_common_name", "host_subject_id", "age", "sex", "body_product", "tot_mass", "diet", "family_relationship", "genotype", "SampleID") 
  samdf <- samdf[rownames(seqtabAll), keep.cols]
```
  
```{r, include=FALSE}
  #The full suite of data for this study – the sample-by-sequence feature table, the sample metadata, 
  #the sequence taxonomies, and the phylogenetic tree – can now be combined into a single object.
# Remove mock sample
```

```{r}
  ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxTab),phy_tree(fitGTR$tree))
  ps <- prune_samples(sample_names(ps) != "Mock", ps) 
```

##Using phyloseq

```{r, include=FALSE}
# Using phyloseq
  # phyloseq is an R package 
  # table metadonnées des OTU

# Loading the data
  # pas beosin de le faire (recuperer objet phylosec sur lien)
  # "https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds"
```

###Filtering

####Taxonomic Filtering
```{r}

    # on peut enlever seq en se basant sur asignation taxonomique
    # seq non indentifiée (quand phylum est null ou uncharacterize)
    rank_names(ps)
    table(tax_table(ps)[, "Phylum"], exclude = NULL)
    ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))

    prevdf = apply(X = otu_table(ps),
                  MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
                   FUN = function(x){sum(x > 0)})
```

Add taxonomy and total read counts to this data.frame
```{r}
    prevdf = data.frame(Prevalence = prevdf,
                        TotalAbundance = taxa_sums(ps),
                        tax_table(ps))
```

Compute the total and average prevalences of the features in each phylum.
```{r}
    plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

```

Define phyla to filter
```{r}    
      filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
```

Filter entries with unidentified Phylum.
```{r}   
      ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
      ps1
```

```{r, include=FALSE}
#.cran_packages <- c( "shiny","miniUI", "caret", "pls", "e1071", "ggplot2", "randomForest", "dplyr", "ggrepel", "nlme", "devtools","reshape2", "PMA", "structSSI", "ade4","ggnetwork", "intergraph", "scales")
#.github_packages <- c("jfukuyama/phyloseqGraphTest")
#.bioc_packages <- c("genefilter", "impute")
```

```{r, include=FALSE}
#.inst <- .cran_packages %in% installed.packages()
#if (any(!.inst)){
#  install.packages(.cran_packages[!.inst],repos = "http://cran.rstudio.com/")
#}
```

```{r, include=FALSE}
#.inst <- .github_packages %in% installed.packages()
#if (any(!.inst)){
#  devtools::install_github(.github_packages[!.inst])
#}
```

```{r, include=FALSE}
#.inst <- .bioc_packages %in% installed.packages()
#if(any(!.inst)){BiocManager::install(.bioc_packages[!.inst])
#}
```


####Prevalence Filtering

Subset to the remaining phyla
```{r}
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
```

Include a guess for parameter
```{r}
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) + geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) + scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") + facet_wrap(~Phylum) + theme(legend.position="none")
```

Define prevalence threshold as 5% of total samples
```{r}
  prevalenceThreshold = 0.05 * nsamples(ps)
  prevalenceThreshold
```

Execute prevalence filter, using `prune_taxa()` function
```{r}
  keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
  ps2 = prune_taxa(keepTaxa, ps)
``` 


###Agglomerate taxa

How many genera would be present after filtering?
```{r} 
  length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
  ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

```{r} 
  h1 = 0.4
  ps4 = tip_glom(ps2, h = h1)
```

```{r} 
  multiPlotTitleTextSize = 15
  p2tree = plot_tree(ps2, method = "treeonly",ladderize = "left",title = "Before Agglomeration") + theme(plot.title = element_text(size = multiPlotTitleTextSize)) 
  p3tree = plot_tree(ps3, method = "treeonly", ladderize = "left", title = "By Genus") + theme(plot.title = element_text(size = multiPlotTitleTextSize))
  p4tree = plot_tree(ps4, method = "treeonly",ladderize = "left", title = "By Height") + theme(plot.title = element_text(size = multiPlotTitleTextSize))
```

Group plots together:
```{r}  
  grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
``` 


###Abundance value transformation

Arbitrary subset, based on Phylum, for plotting
```{r}  
  plot_abundance = function(physeq,title = "", Facet = "Order", Color = "Phylum"){
      p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
      mphyseq = psmelt(p1f)
      mphyseq <- subset(mphyseq, Abundance > 0)
     ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",color = Color, fill = Color)) +geom_violin(fill = NA) + geom_point(size = 1, alpha = 0.3, position = position_jitter(width = 0.3)) + facet_wrap(facets = Facet) + scale_y_log10()+ theme(legend.position="none")
  }

```
 
Transform to relative abundance. Save as new object.
```{r}
  ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```

```{r}
  plotBefore = plot_abundance(ps3,"")
  plotAfter = plot_abundance(ps3ra,"")
  # Combine each plot into one graphic.
  grid.arrange(nrow = 2,  plotBefore, plotAfter)
```

###Subset by taxonomy
```{r}  
  psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
  plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```

###Preprocessing
```{r}
  qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")
  qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```

```{r}
  sample_data(ps)$age_binned <- cut(sample_data(ps)$age,breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") + labs(col = "Binned Age") +coord_fixed(sqrt(evals[2] / evals[1]))
```

```{r}
rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```


##Different Ordination Projections

```{r}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```

```{r}
which(!rowSums(otu_table(ps)) > 1000)
```

```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned", shape = "family_relationship") + labs(col = "Binned Age", shape = "Litter")+ coord_fixed(sqrt(evals[2] / evals[1]))
```

```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned", label= "SampleID", shape = "family_relationship") + labs(col = "Binned Age", shape = "Litter")+ coord_fixed(sqrt(evals[2] / evals[1]))
```

```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") + coord_fixed(sqrt(evals[2] / evals[1]))
```

```{r}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") + coord_fixed(sqrt(evals[2] / evals[1])) + labs(col = "Binned Age", shape = "Litter")
```

```{r, include=FALSE}
#Why are the ordination plots so far from square?
#Aspect ratio of ordination plots
#PCA on ranks
```


###Why are the ordination plots so far from square?

####Aspect ratio of ordination plots

####PCA on ranks
```{r}
abund <- otu_table(pslog)
abund_ranks <- t(apply(abund, 1, rank))

abund_ranks <- abund_ranks - 329
abund_ranks[abund_ranks < 1] <- 1
```

```{r}
library(dplyr)
library(reshape2)
abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

sample_ix <- sample(1:nrow(abund_df), 8)
ggplot(abund_df %>%
         filter(sample %in% abund_df$sample[sample_ix])) +geom_point(aes(x = abund, y = rank, col = sample),
             position = position_jitter(width = 0.2), size = 1.5) +labs(x = "Abundance", y = "Thresholded rank") + scale_color_brewer(palette = "Set2")
```

```{r}
library(ade4)
ranks_pca <- dudi.pca(abund_ranks, scannf = FALSE, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co,seq = colnames(abund_ranks))

tax <- tax_table(ps) %>%
  data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(ps)))
row_scores <- row_scores %>%
  left_join(sample_data(pslog))
col_scores <- col_scores %>%
  left_join(tax)
```

```{r}
evals_prop <- 100 * (ranks_pca$eig / sum(ranks_pca$eig))
ggplot() +
  geom_point(data = row_scores, aes(x = li.Axis1, y = li.Axis2), shape = 2) +
  geom_point(data = col_scores, aes(x = 25 * co.Comp1, y = 25 * co.Comp2, col = Order),
             size = .3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  facet_grid(~ age_binned) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
       y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  coord_fixed(sqrt(ranks_pca$eig[2] / ranks_pca$eig[1])) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```

####Canonical correspondence

```{r}
ps_ccpna <- ordinate(pslog, "CCA", formula = pslog ~ age_binned + family_relationship)
```

```{r}
library(ggrepel)
ps_scores <- vegan::scores(ps_ccpna)
sites <- data.frame(ps_scores$sites)
sites$SampleID <- rownames(sites)
sites <- sites %>%
  left_join(sample_data(ps))

species <- data.frame(ps_scores$species)
species$otu_id <- seq_along(colnames(otu_table(ps)))
species <- species %>%
  left_join(tax)
evals_prop <- 100 * ps_ccpna$CCA$eig[1:2] / sum(ps_ccpna$CA$eig)
ggplot() + geom_point(data = sites, aes(x = CCA1, y = CCA2), shape = 2, alpha = 0.5) + geom_point(data = species, aes(x = CCA1, y = CCA2, col = Order), size = 0.5) + geom_text_repel(data = species %>% filter(CCA2 < -2), aes(x = CCA1, y = CCA2, label = otu_id), size = 1.5, segment.size = 0.1) + facet_grid(. ~ family_relationship) + guides(col = guide_legend(override.aes = list(size = 3))) + labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)), y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) + scale_color_brewer(palette = "Set2") + coord_fixed(sqrt(ps_ccpna$CCA$eig[2] / ps_ccpna$CCA$eig[1])*0.45   ) + theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
